{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import helper_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an example for cortex release 0.21 and may not deploy correctly on other releases of cortex\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import OrderedDict \n",
    "from itertools import islice\n",
    "import json\n",
    "import ipdb\n",
    "\n",
    "import boto3\n",
    "\n",
    "import redis\n",
    "\n",
    "from utils import helper_functions, redis_cache_mechanisms\n",
    "\n",
    "\n",
    "class PythonPredictor:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # download the information retrieval model trained on MS-MARCO dataset\n",
    "        #self.embedder = SentenceTransformer('distilroberta-base-msmarco-v2')\n",
    "        self.embedder = SentenceTransformer('./models/distilroberta-base-msmarco-v2')\n",
    "        \n",
    "        # set the environment variables\n",
    "        self.redis_host = '127.0.0.1'\n",
    "        self.redis_port = 6379\n",
    "\n",
    "\n",
    "        self.aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "        self.aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "        \n",
    "           \n",
    "        # establish connection with s3 bucket\n",
    "        \n",
    "        try:  \n",
    "            self.s3 = boto3.client('s3', aws_access_key_id=self.aws_access_key_id , aws_secret_access_key=self.aws_secret_access_key)\n",
    "            print('Connected to s3 bucket!')\n",
    "        except Exception as ex:\n",
    "            print('\\n\\naws client error:', ex)\n",
    "            exit('Failed to connect to s3 bucket, terminating.')\n",
    "        \n",
    "        \n",
    "        # establish connection to redis server to be used as data store persistence\n",
    "\n",
    "        try:\n",
    "            self.r = redis.StrictRedis(host=self.redis_host, port=self.redis_port, decode_responses=True)\n",
    "            self.r.ping()\n",
    "            print('Connected to redis cache!')\n",
    "        except Exception as ex:\n",
    "            print('\\n\\nredis client error:', ex)\n",
    "            exit('Failed to connect to redis, terminating.')\n",
    "\n",
    "        \n",
    "        self.dir = 'tmp'\n",
    "\n",
    "\n",
    "\n",
    "        if os.path.exists(self.dir):\n",
    "            shutil.rmtree(self.dir)\n",
    "        os.makedirs(self.dir)                                           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, payload):\n",
    "        \n",
    "        # extract values from the request payload\n",
    "        \n",
    "        # sess stores a file's uuid\n",
    "        # a unique identifier to link to an uploaded file's text file, encodings and top words\n",
    "        sess = payload[\"uuid\"]\n",
    "     \n",
    "        query = payload[\"text\"]\n",
    "\n",
    "        max_results =  payload[\"top\"]\n",
    "        \n",
    "        acc_greater_than  = payload[\"accuracyGreaterThan\"]\n",
    "        \n",
    "        cache_bool_value = redis_cache_mechanisms.check_if_request_to_be_cached(self, sess, query, max_results)\n",
    "        \n",
    "        print('are we caching the values:', cache_bool_value)\n",
    "                \n",
    "        if cache_bool_value:\n",
    "            \n",
    "            # as caching has to be done we request for 50 more lines and cache them\n",
    "            # however we return the exact requested amount of lines to the client\n",
    "            max_results+=50\n",
    "            \n",
    "            # check if the files for the corresponding file id are present on the local disk or not\n",
    "            # return 0 if there's no folder present for the file\n",
    "            sess_dir_find = glob.glob('tmp/'+sess)\n",
    "            new_disk_sess = True if len(sess_dir_find)==0 else False\n",
    "\n",
    "            if new_disk_sess:\n",
    "                # create new cache disk session direct\n",
    "\n",
    "                helper_functions.download_text_file_and_embeddings_from_s3_bucket(self, sess)\n",
    "\n",
    "                corpus, corpus_embeddings = helper_functions.load_text_file_and_embeddings(self, sess)\n",
    "\n",
    "            else:\n",
    "\n",
    "\n",
    "                # accessing from already downloaded encodings and files from disk\n",
    "\n",
    "                print('ðŸ˜‰ got you\\'ve covered, model alread encoded ðŸ¤˜')\n",
    "\n",
    "                corpus, corpus_embeddings = helper_functions.load_text_file_and_embeddings(self, sess)\n",
    "\n",
    "\n",
    "            queries = [str(query)]\n",
    "            \n",
    "\n",
    "            query_embeddings = self.embedder.encode(queries)\n",
    "\n",
    "            queries_and_embeddings=(queries, query_embeddings)\n",
    "            corpus_and_embeddings=(corpus, corpus_embeddings)\n",
    "\n",
    "            response = helper_functions.cluster(self, corpus_and_embeddings, queries_and_embeddings, max_results, acc_greater_than)\n",
    "            \n",
    "            #ipdb.set_trace()\n",
    "            #-------------------------------Redis cache layer---------------------------------\n",
    "            \n",
    "            redis_cache_mechanisms.cache_response_to_redis(self, sess, query, response, max_results)\n",
    "            \n",
    "            #----------------------------------------------------------------------------------\n",
    "\n",
    "            response = OrderedDict(islice(response.items(), 0, payload['top']))\n",
    "            \n",
    "            return response\n",
    "\n",
    "        else:\n",
    "\n",
    "            # return from redis cache!\n",
    "\n",
    "            \n",
    "            print('file available in redis cache! ðŸ˜‡')\n",
    "\n",
    "            response_cache = redis_cache_mechanisms.get_cache_data_from_redis(self, sess, query, max_results)\n",
    "            \n",
    "            \n",
    "            return response_cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to s3 bucket!\n",
      "Connected to redis cache!\n"
     ]
    }
   ],
   "source": [
    "pr = PythonPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 0eb1f558-b4e0-4118-80f1-c7b3e1741fca\n",
    "# 3dc5ea3d-d5e1-4946-91ed-be0d63af8a12\n",
    "# c514e5d4-e0c9-4c6a-a35a-d3ad706c419b\n",
    "\n",
    "payload = {\n",
    "    \"uuid\": \"3dc5ea3d-d5e1-4946-91ed-be0d63af8a12\", \n",
    "    \"text\": \"money\",\n",
    "    \"top\": 54,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in check for cache or not\n",
      "query not present in cache:  False\n",
      "number of requested lines exceed the ones in cache:  False\n",
      "are we caching the values: False\n",
      "file available in redis cache! ðŸ˜‡\n"
     ]
    }
   ],
   "source": [
    "resp = pr.predict(payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Cybermoney will become the new money of the     Information Age, replacing the paper money of Industrialism\": 0.5772, \"Unique, anonymous, and verifiable, this money will accommodate the largest transactions\": 0.5653, \"Paper money in the West began as warehouse or safe-deposit receipts for quantities of precious metals\": 0.5416, \"This new digital form of money is destined to play a pivotal role in cybercommerce\": 0.5248, \"The new digital money of the Information Age will return control over the medium of exchange to the owners of wealth, who wish to preserve it, rather than to nation-states that wish to spirit it away\": 0.5158, \"\\\\\"17          Digital money on global computer networks will make every object on Hayek\\'s continuum of liquidity more liquid-except government paper\": 0.4879, \"The names of traditional currencies like the \\\\\"pound\\\\\" and the \\\\\"peso\\\\\" reflect the fact that they originated as measures of weight of specific quantities of precious metals\": 0.4699, \"Cash transcended the limitations of barter, and its advantages will continue to be compelling in most transactions\": 0.4521, \"Paper money also contributed significantly to the power of the state, not only by generating profits from depreciating the currency, but by giving the state leverage over who could accumulate wealth\": 0.4495, \"What we find is rather a continuum in which objects of various degrees of liquidity, or with values which can fluctuate independently of each other, shade into each other in the degree to which they function as money\": 0.4378, \"\\\\\" 16 CYBERCASH            Now the advent of the Information Age implies another revolution in the character of money\": 0.4361, \"Use of cybermoney facilitates very-low-cost simultaneous billing, in which accounts are debited with use\": 0.4354, \"Even where different pricing measures are used, or certain transactions continue to be denominated in national currencies, cybermoney will serve the consumers far better than nationalized money ever did\": 0.4262, \"In the new millennium, cybermoney controlled by private markets will supersede flat money issued by governments\": 0.4246, \"Not Subject to Counterfeiting           While paper money will no doubt remain in circulation as a residual medium of exchange for the poor and computer-illiterate, money for high-value transactions will be privatized\": 0.4204, \"Hayek argued, there is \\\\\"no clear distinction between money and non-money\": 0.4139, \"Cybermoney will no longer be denominated only in national units like the paper money of the industrial period\": 0.4121, \"\\\\\" He wrote, \\\\\" although we usually assume there is a sharp line of distinction between what is money and what is not-and the law generally tries to make such a distinction-so far as the causal effects of monetary events are concerned, there is no such clear difference\": 0.4059, \"The capacity of digital money to deliver micropayments will facilitate the emergence of new types of businesses that heretofore could not have existed, specializing in organizing the distribution of low-value information\": 0.4031, \"As Huizinga said, \\\\\"Very little property is, in the modern sense, liquid, while power is not yet associated predominantly with money; it is still rather inherent in the person and depends on a sort of religious awe which he inspires; it makes itself felt by pomp and magnificence, or a numerous train of faithful followers\": 0.399, \"Cybermoney will pay lower interest rates than national currencies and will probably also carry explicit transaction costs\": 0.3968, \"Unlike the paper-money receipts issued by governments during the gold-standard era, which could be duplicated at will, the new digital gold standard or its barter equivalents will be almost impossible to counterfeit for the fundamental mathematical reason that it is all but impossible to unravel the product of multihundred-digit prime numbers\": 0.3856, \"Offsetting these apparent drawbacks to holding balances in digital money will be enhanced protection against losses due to predatory taxes and inflation\": 0.3781, \"In some          ways, the simplest thing a man can do if he wants money is to take it\": 0.3767, \"The world reserve currency during this period, the U\": 0.3753, \"Roman coinage was still employed, but it practically disappeared from circulation\": 0.3666, \"Contracting Leverage           The emergence of digital money will not only defeat inflation once and for all; it will also contract leverage in the banking systems of the world\": 0.3661, \"Cybermoney will be all but impossible to counterfeit in this way, officially or unofficially\": 0.363, \"Still other governments may adapt to the opportunities created by the information economy, and facilitate local transactions in cybermoney\": 0.3581, \") The greatest revolution in money prior to the Information Age came with the advent of industrialism\": 0.3579, \"The relative advantage of holding land as compared to money capital was falling\": 0.3515, \"Money was needed to do that, but money itself could not win a battle\": 0.3457, \"Soon, you will pay for almost any transaction over the Net or World Wide Web at the same time you place it, using cybercash\": 0.3443, \"Dialing Without Dollars           Inevitably, this new cybermoney will be denationalized\": 0.3434, \"As Abu-Lughod put it, \\\\\"when paper money backed by the state become the approved currency, the chances for amassing capital in opposition to or independent of the state machinery became difficult\": 0.3433, \"dollar deposits in Paraguayan banks over the last three decades\": 0.3421, \"If all the disguised profits of issuing money were extinguished, a new method of payment would be needed to compensate the issuers of currency directly\": 0.342, \"But it will be as easy for the computer to distinguish these demoninations of digital money as if they were the size of a chipmunk and a rhinoceros\": 0.3357, \"(The introduction of coinage helped launch the five-hundred-year cycle of expansion in the ancient economy that culminated with the birth of Christ and the lowest interest rates before the modern period\": 0.3353, \"Quoted in Henry Mark Holzer, Governments\\' Money Monopoly (New York: Books in Focus, 1981), p\": 0.3352, \"The Transaction Cost of \\\\\"Free\\\\\" Currency           Use of this new cybermoney will substantially free you from the power of the state\": 0.3335, \"John Dos Passos, The Big Money (New York: Harcourt, Brace & Co\": 0.3264, \"Private banks took deposits and issued their own private currencies backed by gold bullion\": 0.3231, \"Tens of billions, then ultimately hundreds of billions of dollars will be controlled by hundreds of thousands, then millions of Sovereign Individuals\": 0.3231, \"This new form of money will reset the odds, reducing the capacity of the world\\'s nation- states to determine who becomes a Sovereign Individual\": 0.3226, \"Why should they? Control over money will migrate from the halls of power to the global marketplace\": 0.3221, \"* Thinking of inflation as a transaction fee for the convenience of holding currency may be unusual, but consider it closely\": 0.3219, \"Cyberbroking           You will be able to use cybermoney to make investments as well as pay for services and products\": 0.3217, \"This means not     only a change in the fortunes of banknote printers, it implies the death of     inflation as an effective means by which nation-states can commandeer     resources\": 0.3164, \"You will soon be able to deal in digital money from a private firm, issued much as American Express issues traveler\\'s checks as receipts for cash\": 0.313, \"Because it will probably be gold-linked, cybermoney will also benefit from the appreciation of gold\": 0.313, \"Most of the assets of the typical retiree are not real wealth but \\\\\"transcendental capital,\\\\\" the expected value of transfer payments\": 0.3126, \"In the past, megapolitical transitions have been associated with changes in the character of money\": 0.3089, \"As cybercommerce begins, it will lead inevitably to cybermoney\": 0.3073, \"The fastest-growing and most important new economy of the next century will     not be China but the cybereconomy\": 0.3033}'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'Not only will they tend to have less recourse to banks for borrowing; firms in the Information Age are also likely to have fewer physical assets to capture'\n",
    "b = 'Tax-free money already compounds far faster offshore than onshore funds still subject to the high tax burden imposed by the twentieth-century nation-state'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b5f63b256df\n",
      "6b942de42fa\n"
     ]
    }
   ],
   "source": [
    "line_hash_id = get_sliced_hash(a)\n",
    "print(line_hash_id)\n",
    "print(get_sliced_hash(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def hash_it(string):\n",
    "    '''\n",
    "    sha1 hash creates a 40 character string encoded as hexadecimal.\n",
    "    hexadecimal bit contains 2^4 characters\n",
    "    so if we slice the sha1 output to first 9 bits.\n",
    "    Ideally it should map 2^(4*9) number of strings. ~= 6.8*10^10 = 68 billion lines\n",
    "    For practical cases, taking into consideration the birthday problem and other collision issues,\n",
    "    A collision can be considered to take place roughly every 2^(4*n*0.5) where n is the number of bits\n",
    "    '''\n",
    "\n",
    "    # for our purposes we will keep first 11 bits for line ids, which can map atleast 4 million lines (2^(4*0.5*11))\n",
    "    # because an average 1MB book contains 6000 strings\n",
    "    # if we max out the book size to 50MB and containing 300,000 lines, we still have additional 2.7 Million lines to spare\n",
    "\n",
    "    # for query ids also we will keep first 11 bits, which can map atleast 4 million query. Enough to start with\n",
    "\n",
    "    return hashlib.sha1(string.encode('utf-8')).hexdigest()\n",
    "\n",
    "\n",
    "def get_sliced_hash(string):\n",
    "\n",
    "    # number of bits from sha1 hash to be used for line and query ids\n",
    "    # chech hash_it function for more details on why we are slicing a part of sha1 hash\n",
    "    HASH_SHA1_BITS_RETAIN = 11\n",
    "    \n",
    "\n",
    "    string_hash = hash_it(string)\n",
    "    hash_id = string_hash[:HASH_SHA1_BITS_RETAIN]\n",
    "\n",
    "    return hash_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5]\n",
    "print(a[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#og\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, b in list(a.items()):\n",
    "    print(l, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = pr.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "redis_host = \"localhost\"\n",
    "redis_port = 6379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.StrictRedis(host=redis_host, port=redis_port, decode_responses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1613237734379-0', {'1613237734379-0': '0.6601'}),\n",
       " ('1613237734380-0', {'1613237734379-1': '0.6288'}),\n",
       " ('1613237734380-1', {'1613237734380-0': '0.5703'})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.xrange('3dc5ea3d-d5e1-4946-91ed-be0d63af8a12:query_id:1613237734378-0:match_lines', '-', '+', count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setbit user:user_id:bookmarks:query_id line_id 1\n",
    "r.setbit('user:1:uuid:2:bookmarks:query_id', 113, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.get('user:1:uuid:2:bookmarks:query_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000\n"
     ]
    }
   ],
   "source": [
    "s = r.get('user:1:uuid:2:bookmarks:query_id')\n",
    "bitmap = \"\"\n",
    "for c in s:\n",
    "    x = ord(c)\n",
    "    str = bin(x).split('b')[1]\n",
    "    if len(str) < 8 : \n",
    "       str = '0' * (8-len(str)) + str\n",
    "    bitmap += str\n",
    "print(bitmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XADD mystream * name Sara surname OConnor\n",
    "\n",
    "a = r.xadd('qid1:', {'content': 'enlightenment is the space between your thoughts', 'bookmark': 959 })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.xlen('qid1:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "r.xrange('qid1:', '-', '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 Âµs, sys: 2 Âµs, total: 8 Âµs\n",
      "Wall time: 14.5 Âµs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "r.xrevrange('qid13:', '+', '-', count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c8ceaa59d3031a316e2e212b2b1b80213368b10b\n",
      "c8ceaa59d30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c8'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_hash_id = hash_it('violence')[:11]\n",
    "print(hash_it('violence'))\n",
    "print(query_hash_id)\n",
    "query_hash_id[:2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1613237734378-0\n"
     ]
    }
   ],
   "source": [
    "query_id = r.hget(payload['uuid']+':query_to_id:'+query_hash_id[:2], query_hash_id[2::])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "with open('tmp/3dc5ea3d-d5e1-4946-91ed-be0d63af8a12/text_content.txt', 'r') as file:\n",
    "    file_list = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f816927ca5f3cbf165d67d8b263f0c55270656f1\n",
      "f8 16927ca5f3cbf165d67d8b263f0c55270656f1\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import sys\n",
    "\n",
    "def hash_it(string):\n",
    "    return hashlib.sha1(string.encode('utf-8')).hexdigest()\n",
    "\n",
    "a = hash_it('Missing files are the most common problems with Unix programs, so if the system log and other log information aren\\xe2\\x80\\x99t very helpful and you have nowhere else to turn, strace can be of great use')\n",
    "print(a)\n",
    "print(a[:2], a[2::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'Missing files are the most common problems with Unix programs, so if the system log and other log information aren\\xe2\\x80\\x99t very helpful and you have nowhere else to turn, strace can be of great use'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f816927ca5f3cbf165d67d8b263f0c55270656f1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_it(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Missing files are the most common problems with Unix programs, so if the system log and other log information aren\\xc3\\xa2\\xc2\\x80\\xc2\\x99t very helpful and you have nowhere else to turn, strace can be of great use'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "maxi=0\n",
    "maxline=''\n",
    "for l in file_list:\n",
    "    if len(l) > maxi:\n",
    "        maxi=len(l)\n",
    "        maxline=l\n",
    "    line_id = r.hincrby('ids', 'si:lines', 1)\n",
    "    hash_line = hash_it(l)\n",
    "    r.hset('file:si:'+hash_line[:2], hash_line[3::], line_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "maxi=0\n",
    "maxline=''\n",
    "for l in file_list:\n",
    "    if len(l) > maxi:\n",
    "        maxi=len(l)\n",
    "        maxline=l\n",
    "    line_id = r.hincrby('ids', 'si:lines', 1)\n",
    "    hash_line = hash_it(l)\n",
    "    r.hset('file:si:', l, line_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def hash_it(string):\n",
    "    '''\n",
    "    sha1 hash creates a 40 character string encoded as hexadecimal.\n",
    "    hexadecimal bit contains 2^4 characters\n",
    "    so if we slice the sha1 output to first 9 bits.\n",
    "    Ideally it should map 2^(4*9) number of strings. ~= 6.8*10^10 = 68 billion lines\n",
    "    For practical cases, taking into consideration the birthday problem and other collision issues,\n",
    "    A collision can be considered to take place roughly every 2^(4*n*0.5) where n is the number of bits\n",
    "    '''\n",
    "\n",
    "    # for our purposes we will keep first 10 bits for line ids, which can map atleast 1,048,576 lines (2^(4*0.5*10))\n",
    "    # because an average 1MB book contains 6000 strings\n",
    "    # if we max out the book size to 50MB and containing 300,000 lines, we still have additional 700,000 to spare\n",
    "\n",
    "    # for query ids we will keep first 11 bits, which can map atleast 4 million query. Enough to start with\n",
    "\n",
    "    return hashlib.sha1(string.encode('utf-8')).hexdigest()\n",
    "\n",
    "\n",
    "def get_query_hash(string):\n",
    "\n",
    "    # number of bits from sha1 hash to be used for line and query ids\n",
    "    # chech hash_it function for more details on why we are slicing a part of sha1 hash\n",
    "    QUERY_HASH_SHA1_BITS_RETAIN = 11\n",
    "    \n",
    "\n",
    "    query_hash = hash_it(string)\n",
    "    query_hash_id = query_hash[:QUERY_HASH_SHA1_BITS_RETAIN]\n",
    "\n",
    "    return query_hash_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_hash_id = get_query_hash('violence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id_val = r.hget(payload['uuid']+':query_to_id:'+query_hash_id[:2], query_hash_id[2::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.xlen(payload['uuid']+':query_id:'+str(query_id_val)+':match_lines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('pyenv': venv)",
   "language": "python",
   "name": "python38764bitpyenvvenvb347c22ffcac4343aa1ac3022caaa842"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
