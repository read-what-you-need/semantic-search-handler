{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import helper_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an example for cortex release 0.21 and may not deploy correctly on other releases of cortex\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import OrderedDict \n",
    "from itertools import islice\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "\n",
    "import redis\n",
    "\n",
    "from utils import helper_functions, redis_cache_mechanisms\n",
    "\n",
    "\n",
    "class PythonPredictor:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # download the information retrieval model trained on MS-MARCO dataset\n",
    "        #self.embedder = SentenceTransformer('distilroberta-base-msmarco-v2')\n",
    "        self.embedder = SentenceTransformer('./models/distilroberta-base-msmarco-v2')\n",
    "        \n",
    "        # set the environment variables\n",
    "        self.redis_host = '127.0.0.1'\n",
    "        self.redis_port = 6379\n",
    "\n",
    "\n",
    "        self.aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "        self.aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "        \n",
    "           \n",
    "        # establish connection with s3 bucket\n",
    "        \n",
    "        try:  \n",
    "            self.s3 = boto3.client('s3', aws_access_key_id=self.aws_access_key_id , aws_secret_access_key=self.aws_secret_access_key)\n",
    "            print('Connected to s3 bucket!')\n",
    "        except Exception as ex:\n",
    "            print('\\n\\naws client error:', ex)\n",
    "            exit('Failed to connect to s3 bucket, terminating.')\n",
    "        \n",
    "        \n",
    "        # establish connection to redis server to be used as data store persistence\n",
    "\n",
    "        try:\n",
    "            self.r = redis.StrictRedis(host=self.redis_host, port=self.redis_port, decode_responses=True)\n",
    "            self.r.ping()\n",
    "            print('Connected to redis cache!')\n",
    "        except Exception as ex:\n",
    "            print('\\n\\nredis client error:', ex)\n",
    "            exit('Failed to connect to redis, terminating.')\n",
    "\n",
    "        \n",
    "        self.dir = 'tmp'\n",
    "\n",
    "\n",
    "\n",
    "        if os.path.exists(self.dir):\n",
    "            shutil.rmtree(self.dir)\n",
    "        os.makedirs(self.dir)                                           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, payload):\n",
    "        \n",
    "        # extract values from the request payload\n",
    "        \n",
    "        # sess stores a file's uuid\n",
    "        # a unique identifier to link to an uploaded file's text file, encodings and top words\n",
    "        sess = payload[\"uuid\"]\n",
    "     \n",
    "        query = payload[\"text\"]\n",
    "\n",
    "        max_results =  payload[\"top\"]\n",
    "        \n",
    "        acc_greater_than  = payload[\"accuracyGreaterThan\"]\n",
    "        \n",
    "        cache_bool_value = redis_cache_mechanisms.check_if_request_to_be_cached(self, sess, query, max_results)\n",
    "        \n",
    "        print('are we caching the values:', cache_bool_value)\n",
    "                \n",
    "        if cache_bool_value:\n",
    "            \n",
    "            # as caching has to be done we request for 50 more lines and cache them\n",
    "            # however we return the exact requested amount of lines to the client\n",
    "            max_results+=50\n",
    "            \n",
    "            # check if the files for the corresponding file id are present on the local disk or not\n",
    "            # return 0 if there's no folder present for the file\n",
    "            sess_dir_find = glob.glob('tmp/'+sess)\n",
    "            new_disk_sess = True if len(sess_dir_find)==0 else False\n",
    "\n",
    "            if new_disk_sess:\n",
    "                # create new cache disk session direct\n",
    "\n",
    "                helper_functions.download_text_file_and_embeddings_from_s3_bucket(self, sess)\n",
    "\n",
    "                corpus, corpus_embeddings = helper_functions.load_text_file_and_embeddings(self, sess)\n",
    "\n",
    "            else:\n",
    "\n",
    "\n",
    "                # accessing from already downloaded encodings and files from disk\n",
    "\n",
    "                print('ðŸ˜‰ got you\\'ve covered, model alread encoded ðŸ¤˜')\n",
    "\n",
    "                corpus, corpus_embeddings = helper_functions.load_text_file_and_embeddings(self, sess)\n",
    "\n",
    "\n",
    "            queries = [str(query)]\n",
    "            \n",
    "\n",
    "            query_embeddings = self.embedder.encode(queries)\n",
    "\n",
    "            queries_and_embeddings=(queries, query_embeddings)\n",
    "            corpus_and_embeddings=(corpus, corpus_embeddings)\n",
    "\n",
    "            response = helper_functions.cluster(self, corpus_and_embeddings, queries_and_embeddings, max_results, acc_greater_than)\n",
    "            \n",
    "            redis_cache_mechanisms.cache_response_to_redis(self, sess, query, response)\n",
    "\n",
    "            response = OrderedDict(islice(response.items(), 0, payload['top']))\n",
    "            \n",
    "            return response\n",
    "\n",
    "        else:\n",
    "\n",
    "            # return from redis cache!\n",
    "\n",
    "            print('file available in redis cache! ðŸ˜‡')\n",
    "\n",
    "            response_cache = redis_cache_mechanisms.get_cache_data_from_redis(self, sess, query, max_results)\n",
    "            \n",
    "            return response_cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to s3 bucket!\n",
      "Connected to redis cache!\n"
     ]
    }
   ],
   "source": [
    "pr = PythonPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 0eb1f558-b4e0-4118-80f1-c7b3e1741fca\n",
    "# 3dc5ea3d-d5e1-4946-91ed-be0d63af8a12\n",
    "# c514e5d4-e0c9-4c6a-a35a-d3ad706c419b\n",
    "\n",
    "payload = {\n",
    "    \"uuid\": \"3dc5ea3d-d5e1-4946-91ed-be0d63af8a12\", \n",
    "    \"text\": \"love\",\n",
    "    \"top\": 10,\n",
    "    \"accuracyGreaterThan\": 0.2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in check for cache or not\n",
      "\n",
      "is query not cached:  False\n",
      "does number of requested lines exceed the ones in cache:  False\n",
      "are we caching the values: False\n",
      "file available in redis cache! ðŸ˜‡\n"
     ]
    }
   ],
   "source": [
    "resp = pr.predict(payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['In the 1960s there was a new wave of free love, partly based on the apparent security of the female contraceptive pill, but also promoted by mood-changing drugs and pop music',\n",
       "  0.3742],\n",
       " ['He wrote: \"Loyalty to one\\'s country, on the other hand, is something we could do without',\n",
       "  0.2976],\n",
       " ['A shared morality in a tolerant society was the ideal of John Locke and of early philosophers of liberty',\n",
       "  0.2912],\n",
       " ['Respect for parents and faithfulness in marriage are the best ways to preserve family life; family life is the best way to bring up morally healthy children',\n",
       "  0.2799],\n",
       " ['\"My word is my bond\" was for them an absolute principle', 0.2694],\n",
       " ['The winners, the diarist wrote, were those who made love with those courtesans the greatest number of times',\n",
       "  0.2694],\n",
       " ['\" That makes a very fine phrase, and a very fine aspiration, but \"life, liberty and estate\" is more down to earth than \"life, liberty, and the pursuit of                                                298   happiness',\n",
       "  0.2631],\n",
       " ['\"the highest perfection of intellectual nature lies in a careful pursuit of true and solid happiness, so the care of ourselves that we mistake not imaginary for real happiness, is the necessary foundation of our liberty',\n",
       "  0.2563],\n",
       " ['The powerful energetic affirmation that reassures hearts creates acts-that which is said is produced',\n",
       "  0.2517],\n",
       " ['22           In short, The Prince was a radical work that spelled out a modern recipe whereby an aspiring ruler could succeed in advancing his career at any cost to others',\n",
       "  0.2503],\n",
       " ['This sense that virtue is dynamic, that it consists in the effort rather than the result, developed strongly in the nineteenth century, and in different ways',\n",
       "  0.2444]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in check for cachce or not\n",
      "file available in redis cache! ðŸ˜‡\n"
     ]
    }
   ],
   "source": [
    "resp = pr.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "redis_host = \"localhost\"\n",
    "redis_port = 6379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.StrictRedis(host=redis_host, port=redis_port, decode_responses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "with open('tmp/3dc5ea3d-d5e1-4946-91ed-be0d63af8a12/text_content.txt', 'r') as file:\n",
    "    file_list = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import sys\n",
    "\n",
    "def hash_it(string):\n",
    "    return hashlib.sha1(string.encode('utf-8')).hexdigest()\n",
    "\n",
    "a = hash_it(' You could have pocketed anaverage real return of more than 30 percent annually in U')\n",
    "print(a)\n",
    "print(a[:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "maxi=0\n",
    "maxline=''\n",
    "for l in file_list:\n",
    "    if len(l) > maxi:\n",
    "        maxi=len(l)\n",
    "        maxline=l\n",
    "    line_id = r.hincrby('ids', 'si:lines', 1)\n",
    "    hash_line = hash_it(l)\n",
    "    r.hset('file:si:'+hash_line[:2], hash_line[3::], line_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "maxi=0\n",
    "maxline=''\n",
    "for l in file_list:\n",
    "    if len(l) > maxi:\n",
    "        maxi=len(l)\n",
    "        maxline=l\n",
    "    line_id = r.hincrby('ids', 'si:lines', 1)\n",
    "    hash_line = hash_it(l)\n",
    "    r.hset('file:si:', l, line_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv_semantic",
   "language": "python",
   "name": "pyenv_semantic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
